% !TEX root = ../thesis.tex

\begin{figure}

\centering
\begin{tikzpicture}
  [
    init/.style={  draw,  circle,  inner sep=2pt,  font=\Huge,  join = by -latex},
    act/.style={  draw,  circle,  inner sep=2pt,  font=\Large,  join = by -latex},
    squa/.style={  draw,  inner sep=2pt,  font=\Large,  join = by -latex},
    start chain=2,node distance=13mm
  ]
  \node[on chain=2] (x2) {$x_2$};
  \node[on chain=2,join=by o-latex] {$w_2$};
  \node[on chain=2,init] (sigma) {$\displaystyle\Sigma$};
  \node[on chain=2,act,label=below:{\parbox{2cm}{\centering Activation \\ function}}] {$f$};
  \node[on chain=2,label=below:Output,join=by -latex] {$y$};
      % {[shift={(0.0,-2.0)}]\centering Activation \\ function}

  \begin{scope}[start chain=4]
  \node[on chain=4] at (0,2.0cm) (b) {$ 1$};
  \node[on chain=4,join=by o-latex] (w0) {$b$};
  \end{scope}

  \begin{scope}[start chain=1]
  \node[on chain=1] at (0,1.0cm) (x1) {$x_1$};
  \node[on chain=1,join=by o-latex] (w1) {$w_1$};
  \end{scope}

  \begin{scope}[start chain=3]
  \node[on chain=3,label=below:Inputs] at (0,-1.5cm) (x3) {$x_n$};
  \node[on chain=3,label=below:Weights,join=by o-latex] (w3) {$w_n$};
  \end{scope}
  % \node[label=above:\parbox{2cm}{\centering Bias \\ $b$}] at (sigma|-w1) (b) {};

  \draw[-latex] (w0) -- (sigma);
  \draw[-latex] (w1) -- (sigma);
  \draw[-latex] (w3) -- (sigma);
  % \draw[o-latex] (b) -- (sigma);

  % \draw[decorate,decoration={brace,mirror}] (x1.north west) -- node[left=10pt] {Inputs} (x3.south west);
  % \draw[decorate,decoration={brace,mirror}] (b.north west) -- node[left=10pt] {Bias} (b.south west);
  \path (x2) -- (x3) node [font=\huge, midway, sloped] {$\dots$};
\end{tikzpicture}
\caption{Structure of a basic computational unit of a neural network (perceptron). Input values $x$ are linearly combined according to the set of parameters $W$ and bias $b$ and activation function $f$ is applied.  }
\label{fig:perc}
\end{figure}
